{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bca35a-c64d-46a3-aa05-0f47d26ea393",
   "metadata": {},
   "source": [
    "# GA DSI Project 3: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82732958-4430-46ff-b2f2-138c486445c2",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "With the advent of COVID-19, people have been hit by waves of lockdowns and have taken to starting new hobbies as ways to destress and to indulge in things they have always wanted to do. These include brewing and fermenting, which require little startup equipment but can make delicious alcoholic products for their friends and family. With the growing interest in these techniques, many companies and online services have sprung up to address this need, to provide forums which aspiring homebrewers and winemakers can get information and learn with their peers.\n",
    "\n",
    "A new alcohol company wishes to understand consumer patterns with regard to winemaking and brewing, their two largest services. Since people are mostly stuck at home, many have taken to one or the other to pass time. The company wishes to create a chatbot which can take consumer queries and give them winemaking or homebrewing tips. However, due to these two processes having similar keywords (e.g. fermentation, tank, yeast), this is not a trivial task. To this end, they have requested a machine learning model from us which can identify whether the prospective customer wishes to know about homebrewing or winemaking.\n",
    "\n",
    "To this end, we will be creating a machine learning model using posts from the Enology and Viticulture (r/winemaking) and Homebrewing (r/homebrewing) subreddits to train our model, and use the classifiers we have learnt so far to find the optimal model which can suit their needs and be integrated into their chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e599b559-33fc-45ca-808b-b0e6fa3229d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unholy trinity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# api\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# timing code\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8aee6-ec8d-4d9c-be68-b212dbb9ccf3",
   "metadata": {},
   "source": [
    "# Scraping Data\n",
    "\n",
    "As mentioned above, we will be scraping [r/winemaking](https://www.reddit.com/r/winemaking/) and [r/homebrewing](https://www.reddit.com/r/homebrewing/) to train our model. Since pushshift has a limit on the number of posts we can pull at one go, we will have to create a workaround. In this case, we will pull every row individually, then take the timestamp as the query parameter for the next pull. In this way, our code will be making 1000 queries per subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3b696e-1276-4aed-a7b5-a219413c6355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status code for the winemaking subreddit is: 200\n",
      "The status code for the homebrewing subreddit is: 200\n",
      "The scraping took 250.1583 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "N = 0\n",
    "last = ''\n",
    "reddit_data = []\n",
    "pages = ['winemaking', 'homebrewing']\n",
    "for page in pages:\n",
    "    url = f'https://api.pushshift.io/reddit/search/submission/?subreddit={page}'\n",
    "    print(f'The status code for the {page} subreddit is: {requests.get(url).status_code}')\n",
    "    while N < 1000:\n",
    "        request = requests.get(f'{url}&before={last}')\n",
    "        json = request.json()\n",
    "        for s in json[\"data\"]:\n",
    "            reddit_data.append(s)\n",
    "            N += 1\n",
    "        last = int(s[\"created_utc\"])\n",
    "    N=0\n",
    "    last=''\n",
    "        \n",
    "toc = time.perf_counter()\n",
    "print(f\"The scraping took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47589d-339c-4bba-975d-5f365a50418a",
   "metadata": {},
   "source": [
    "Let's take put the data into a pandas dataframe for easier reference, and confirm that 1000 entries have been scraped for each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5cb151-3837-4c87-9c07-94b4bd30aca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winemaking     1000\n",
       "Homebrewing    1000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = pd.DataFrame(reddit_data)\n",
    "reddit_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0891ebdc-45f3-4bef-b003-808caedeaa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author', 'author_cakeday',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_richtext', 'author_flair_template_id',\n",
       "       'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
       "       'author_fullname', 'author_is_blocked', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'crosspost_parent', 'crosspost_parent_list',\n",
       "       'distinguished', 'domain', 'edited', 'full_link', 'gallery_data',\n",
       "       'gildings', 'id', 'is_created_from_ads_ui', 'is_crosspostable',\n",
       "       'is_gallery', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_richtext',\n",
       "       'link_flair_template_id', 'link_flair_text', 'link_flair_text_color',\n",
       "       'link_flair_type', 'locked', 'media', 'media_embed', 'media_metadata',\n",
       "       'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'poll_data',\n",
       "       'post_hint', 'preview', 'pwls', 'removed_by_category', 'retrieved_on',\n",
       "       'score', 'secure_media', 'secure_media_embed', 'selftext',\n",
       "       'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'subreddit_subscribers', 'subreddit_type', 'suggested_sort',\n",
       "       'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title',\n",
       "       'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url',\n",
       "       'url_overridden_by_dest', 'whitelist_status', 'wls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a3c883-ba10-4204-a1f8-d7ba262674e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>...</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>edited</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>suggested_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Plenox</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_hdu1d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>thesnakewithin</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_2sc63pjf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>handbanana42069</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_8txoqw2b</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>combhonn</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_ay6uj6sh</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>WoodenPear</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1xaou9f0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments           author author_flair_css_class  \\\n",
       "0            []                False           Plenox                   None   \n",
       "1            []                False   thesnakewithin                   None   \n",
       "2            []                False  handbanana42069                   None   \n",
       "3            []                False         combhonn                   None   \n",
       "4            []                False       WoodenPear                   None   \n",
       "\n",
       "  author_flair_richtext author_flair_text author_flair_type author_fullname  \\\n",
       "0                    []              None              text        t2_hdu1d   \n",
       "1                    []              None              text     t2_2sc63pjf   \n",
       "2                    []              None              text     t2_8txoqw2b   \n",
       "3                    []              None              text     t2_ay6uj6sh   \n",
       "4                    []              None              text     t2_1xaou9f0   \n",
       "\n",
       "   author_is_blocked author_patreon_flair  ... secure_media  \\\n",
       "0              False                False  ...          NaN   \n",
       "1              False                False  ...          NaN   \n",
       "2              False                False  ...          NaN   \n",
       "3              False                False  ...          NaN   \n",
       "4              False                False  ...          NaN   \n",
       "\n",
       "  secure_media_embed  author_cakeday  author_flair_background_color  \\\n",
       "0                NaN             NaN                            NaN   \n",
       "1                NaN             NaN                            NaN   \n",
       "2                NaN             NaN                            NaN   \n",
       "3                NaN             NaN                            NaN   \n",
       "4                NaN             NaN                            NaN   \n",
       "\n",
       "   author_flair_template_id author_flair_text_color edited poll_data  \\\n",
       "0                       NaN                     NaN    NaN       NaN   \n",
       "1                       NaN                     NaN    NaN       NaN   \n",
       "2                       NaN                     NaN    NaN       NaN   \n",
       "3                       NaN                     NaN    NaN       NaN   \n",
       "4                       NaN                     NaN    NaN       NaN   \n",
       "\n",
       "  distinguished  suggested_sort  \n",
       "0           NaN             NaN  \n",
       "1           NaN             NaN  \n",
       "2           NaN             NaN  \n",
       "3           NaN             NaN  \n",
       "4           NaN             NaN  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffebf5-adb4-4ace-96c6-f4122f189d9b",
   "metadata": {},
   "source": [
    "We can perform a check on whether there are any posts that are only media which would make our analysis more difficult. There are no entries which are only media thankfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da48d3f-a21d-4515-8a54-e73fe7236ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    media_only\n",
       "Homebrewing  False         1000\n",
       "winemaking   False         1000\n",
       "Name: media_only, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.groupby('subreddit')['media_only'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325510a3-f678-4292-8362-c74068703a62",
   "metadata": {},
   "source": [
    "For our model training purposes, we only need 3 columns:\n",
    "1. the title of the post\n",
    "2. the text of the post\n",
    "3. which subreddit the data came from (dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ccdadbc-54c1-48ec-b6f9-9af0bb762894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit_df = reddit_df[['title', 'selftext', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd89244-9066-4ba4-9c5a-d062dc12f6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is this buildup?</td>\n",
       "      <td></td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Added a bit too much water 200ish ml, asked fo...</td>\n",
       "      <td></td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many vines would you start with?</td>\n",
       "      <td>Hi all- \\n\\n&amp;amp;#x200B;\\n\\nWine lover and avi...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Misc CO2 / Oxygen protection question ...</td>\n",
       "      <td>I have a wine batch that has CO2 naturally dis...</td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's going on in this bottle?</td>\n",
       "      <td></td>\n",
       "      <td>winemaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              What is this buildup?   \n",
       "1  Added a bit too much water 200ish ml, asked fo...   \n",
       "2               How many vines would you start with?   \n",
       "3          Misc CO2 / Oxygen protection question ...   \n",
       "4                    What's going on in this bottle?   \n",
       "\n",
       "                                            selftext   subreddit  \n",
       "0                                                     winemaking  \n",
       "1                                                     winemaking  \n",
       "2  Hi all- \\n\\n&amp;#x200B;\\n\\nWine lover and avi...  winemaking  \n",
       "3  I have a wine batch that has CO2 naturally dis...  winemaking  \n",
       "4                                                     winemaking  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca95dae-1a0b-4e91-8ab0-27ecc507745f",
   "metadata": {},
   "source": [
    "We can now save our data into a csv file to be ready for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b08d2d0a-ae77-431a-a0fc-700127ef7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.to_csv('../data/reddit-data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
